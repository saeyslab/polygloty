---
title: "Polyglot programming for single-cell analysis"
author:
- "Louise Deconinck"
- "Benjamin Rombaut"
- "Robrecht Cannoodt"
date: "9/12/2024"
format:
  revealjs:
    css: slides.css
    toc-depth: 1
    smaller: true
    slide-number: true
    show-slide-number: all
    embed-resources: true
    preview-links: auto
    progress: true
    history: true
    link-external-newwindow: true
jupyter: python3
exectute:
    echo: true
---

# Introduction

1. How do you interact with a package in another language?
2. How do you make you package useable for developers in other languages?

We will be focusing on R & Python

## Summary

**Interoperability** between languages allows analysts to take advantage of the strengths of different ecosystems

**On-disk** interoperability uses standard file formats to transfer data and is typically more reliable

**In-memory** interoperability transfers data directly between parallel sessions and is convenient for interactive analysis

While interoperability is currently possible developers continue to improve the experience

[Single-cell best practices: Interoperability](https://www.sc-best-practices.org/introduction/interoperability.html)

# How do you interact with a package in another language?

1. In-memory interoperability
2. Disk-based interoperability


# How do you make your package useable for developers in other languages?

1. Package-based interoperability
2. Best practices

# Package-based interoperability
or: the question of reimplementation.

- Consider the pros:

  1. Discoverability
  2. Can your package be useful in other domains?
  3. Very user friendly

- Consider the cons:

  1. Think twice: is it worth it?
  2. **It's a lot of work**
  3. How will you keep it up to date?
  4. How will you ensure parity?

# Package-based interoperability

Please learn both R & Python

# Best practices
1. Work with the standards
2. Work with matrices, arrays and dataframes
3. Provide vignettes on interoperability

# In-memory interoperability
![](../book/in_memory/images/imm_overview.png)

# Overview

1. Advantages & disadvantages
2. Pitfalls when using Python & R
2. Rpy2
3. Reticulate

# in-memory interoperability advantages
- no need to write & read results
- useful when you need a limited amount of functions in another language

# in-memory interoperability drawbacks
- not always access to all classes
- data duplication
- you need to manage the environments

# Pitfalls when using Python and R
**Column major vs row major matrices**
In R: every dense matrix is stored as column major

![](../book/in_memory/images/inmemorymatrix.png)

# Pitfalls when using Python and R
**Indexing**

![](../book/in_memory/images/indexing.png)

# Pitfalls when using Python and R
**dots and underscores**

- mapping in rpy2

```python
from rpy2.robjects.packages import importr

d = {'package.dependencies': 'package_dot_dependencies',
     'package_dependencies': 'package_uscore_dependencies'}
tools = importr('tools', robject_translations = d)
```

# Pitfalls when using Python and R
**Integers**

```r 
library(reticulate)
bi <- reticulate::import_builtins()

bi$list(bi$range(0, 5))
# TypeError: 'float' object cannot be interpreted as an integer
```

```r 
library(reticulate)
bi <- reticulate::import_builtins()

bi$list(bi$range(0L, 5L))
# [1] 0 1 2 3 4
```

# Rpy2: basics
- Accessing R from Python
  - `rpy2.rinterface`, the low-level interface
  - `rpy2.robjects`, the high-level interface

```python
import rpy2
import rpy2.robjects as robjects

vector = robjects.IntVector([1,2,3])
rsum = robjects.r['sum']

rsum(vector)
```

# Rpy2: basics

```python
str_vector = robjects.StrVector(['abc', 'def', 'ghi'])
flt_vector = robjects.FloatVector([0.3, 0.8, 0.7])
int_vector = robjects.IntVector([1, 2, 3])
mtx = robjects.r.matrix(robjects.IntVector(range(10)), nrow=5)
```

# Rpy2: numpy

```python
import numpy as np

from rpy2.robjects import numpy2ri
from rpy2.robjects import default_converter

rd_m = np.random.random((10, 7))

with (default_converter + numpy2ri.converter).context():
    mtx2 = robjects.r.matrix(rd_m, nrow = 10)
```

# Rpy2: pandas
```python
import pandas as pd

from rpy2.robjects import pandas2ri

pd_df = pd.DataFrame({'int_values': [1,2,3],
                      'str_values': ['abc', 'def', 'ghi']})

with (default_converter + pandas2ri.converter).context():
    pd_df_r = robjects.DataFrame(pd_df)
```

# Rpy2: sparse matrices

```python
import scipy as sp

from anndata2ri import scipy2ri

sparse_matrix = sp.sparse.csc_matrix(rd_m)

with (default_converter + scipy2ri.converter).context():
    sp_r = scipy2ri.py2rpy(sparse_matrix)
```

# Rpy2: anndata

```python
import anndata as ad
import scanpy.datasets as scd

import anndata2ri

adata_paul = scd.paul15()

with anndata2ri.converter.context():
    sce = anndata2ri.py2rpy(adata_paul)
    ad2 = anndata2ri.rpy2py(sce)
```

# Rpy2: interactivity

```python
%load_ext rpy2.ipython  # line magic that loads the rpy2 ipython extension.
                        # this extension allows the use of the following cell magic

%%R -i input -o output  # this line allows to specify inputs 
                        # (which will be converted to R objects) and outputs 
                        # (which will be converted back to Python objects) 
                        # this line is put at the start of a cell
                        # the rest of the cell will be run as R code
```

# Reticulate

# Disk-based interoperability

## General single cell file formats of interest for Python and R

{{< include ../book/disk_based/_general_file_formats.qmd >}}

## Specialized single cell file formats of interest for Python and R

{{< include ../book/disk_based/_specialized_file_formats.qmd >}}

# Workflows

# Takeaways
