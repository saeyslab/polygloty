---
title: In-memory interoperability
engine: knitr
---

One aproach to interoperability is to work on in-memory representations of one object, and convert these in memory between different programming languages. This does not require you to write out your datasets and read them in in the different programming enivronment, but it does require you to set up an environment in both languages, which can be cumbersome.

One language will act as the main language, and you will intereact with the other language using an FFI (foreign function interface).

![A schematic overview](images/imm_overview.png){#fig-im-overview}

When evaluating R code within a Python program, we will make use of rpy2 to accomplish this. When evaluating Python code within an R program, we will make use of reticulate.

## Pitfalls when mixing Python and R
Python and R are very different programming languages. Here are some pitfalls you might encounter when mixing both languages.

### Column major vs row major
Matrices are stored contiguously in-memory, and are adressed by a single memory addresses, instead of multiple indices along the axis. A translation needs to happen between this single adress and the indices along the axes, and how that translation happens depens on how the matrix is represented in-memory.

![Different in-memory representations](images/inmemorymatrix.png){#fig-imm-matrix}

In R, every dense matrix is represented in column major order. In Python, the standard is row major, but you can specify column major order as well.
There is usually no issue when converting R matrices to Python matrices: reticulate will take care to present these as column major Python matrices. The reverse is not true: all dense (even row major) Python matrices are presented to R as column major matrices. 

If you notice something amiss with your matrices, check whether you need to transpose them or change the row/column major attribute.

### Indexing: 0-based or 1-based
Take care to remember that arrays and matrices in Python are indexed starting from 0 (as in, index 0 refers to the first element), while R uses 1-based indexing, where index 1 refers to the first element.

### Dots in variable names
In R it is very common to use dots in symbols and variable names. This is invalid in Python: dots are used for function calls.
When using rpy2, these dots are usually translated to underscores `_`. If this does not happen automatically, you can specify mappings for these symbols.

### Integers and floating point numbers
In R, unless you explicitly specify, any number is represented as a floating point number.
Python can be more strict about using integers or floating point numbers.

## Rpy2: basic functionality

Rpy2 is a foreign function interface to R. It can be used in the following way:
```{python rpy2_simple_example}
import rpy2
import rpy2.robjects as robjects

vector = robjects.IntVector([1,2,3])
rsum = robjects.r['sum']

rsum(vector)
```

Luckily, we're not restricted to just calling R functions and creating R objects. The real power of this in-memory interoperability lies in the conversion of Python objects to R objects to call R functions on, and then to the conversion of the results back to Python objects.

Rpy2 requires specific conversion rules for different Python objects. It is straightforward to create R vectors from corresponding Python lists:

```{python rpy2_vectors}
str_vector = robjects.StrVector(['abc', 'def', 'ghi'])
flt_vector = robjects.FloatVector([0.3, 0.8, 0.7])
int_vector = robjects.IntVector([1, 2, 3])
mtx = robjects.r.matrix(robjects.IntVector(range(10)), nrow=5)
```

However, for single cell biology, the objects that are most interesting to convert are (count) matrices, arrays and dataframes. In order to do this, you need to import the corresponding rpy2 modules and specify the conversion context.

```{python rpy2_numpy}
import numpy as np

from rpy2.robjects import numpy2ri
from rpy2.robjects import default_converter

rd_m = np.random.random((10, 7))

with (default_converter + numpy2ri.converter).context():
    mtx2 = robjects.r.matrix(rd_m, nrow = 10)
```

```{python rpy2_pandas}
import pandas as pd

from rpy2.robjects import pandas2ri

pd_df = pd.DataFrame({'int_values': [1,2,3],
                      'str_values': ['abc', 'def', 'ghi']})

with (default_converter + pandas2ri.converter).context():
    pd_df_r = robjects.DataFrame(pd_df)
```

One big limitation of rpy2 is the inability to convert sparse matrices: there is no built-in conversion module for scipy.
The `anndata2ri` package provides, apart from functionality to convert SingleCellExperiment objects to an anndata objects, functions to convert sparse matrices.

```{r import_sce, include=FALSE}
# this is added so renv knows that singlecellexperiment needs to be installed
library(SingleCellExperiment)
```

```{python rpy2_sparse}
import scipy as sp

from anndata2ri import scipy2ri

sparse_matrix = sp.sparse.csc_matrix(rd_m)

with (default_converter + scipy2ri.converter).context():
    sp_r = scipy2ri.py2rpy(sparse_matrix)
```

We will showcase how to use anndata2ri to convert an anndata object to a SingleCellExperiment object and vice versa as well:
```{python rpy2_anndata2ri}
import anndata as ad
import scanpy.datasets as scd

import anndata2ri

adata_paul = scd.paul15()

with anndata2ri.converter.context():
    sce = anndata2ri.py2rpy(adata_paul)
    ad2 = anndata2ri.rpy2py(sce)
```


## Reticulate: basic functionality
Reticulate is a foreign function interface in R to Python.

### Interactive sessions
One of the most useful ways to take advantage of in-memory interoperability is to use it in interactive sessions, where you're exploring the data and want to try out some functions non-native to your language of choice.

Jupyter notebooks (and some other notebooks) make this possible from the Python side: using IPython line and cell magic and rpy2, you can easily run an R jupyter cell in your notebooks.

```{python show_magic, eval=FALSE}
%load_ext rpy2.ipython  # line magic that loads the rpy2 ipython extension.
                        # this extension allows the use of the following cell magic

%%R -i input -o output  # this line allows to specify inputs (which will be converted to R objects) and outputs (which will be converted back to Python objects) 
                        # this line is put at the start of a cell
                        # the rest of the cell will be able to be ran as R code

```

### Reticulate basics


## Usecase

### Usecase: ran in Python

We will perform the Compute DE step not in R, but in Python
The pseudobulked data is read in:
```{python load_data}
import anndata as ad

pd_adata = ad.read_h5ad("../usecase/data/pseudobulk.h5ad")
```

Select small molecule and control:
```{python select_sm_control}
sm_name = "Belinostat"
control_name = "Dimethyl Sulfoxide"
```

Creating a DESeq dataset:
This requires a bit more effort: we need to import the DESeq2 package, and combine the default, numpy2ri and pandas2ri converter to convert the count matrix and the obs dataframe.
```{python create_deseq_dataset}
import numpy as np

import rpy2
import rpy2.robjects as robjects

from rpy2.robjects import numpy2ri
from rpy2.robjects import pandas2ri

from rpy2.robjects import default_converter
from rpy2.robjects.packages import importr

DESeq2 = importr("DESeq2")

np_cv_rules = default_converter + numpy2ri.converter + pandas2ri.converter

with np_cv_rules.context() as cv:
    counts_dense = np.transpose(pd_adata.X.astype(np.int32))

    robjects.globalenv["count_data"] = counts_dense
    robjects.globalenv["obs_data"] = pd_adata.obs

```

We can also specify R formulas!
```{python create}
from rpy2.robjects import Formula

design_formula = Formula('~ sm_name + plate_name')

dds = DESeq2.DESeqDataSetFromMatrix(countData = robjects.globalenv["count_data"],
        colData = robjects.globalenv["obs_data"],
        design = design_formula)
```

Run DESeq2:
```{python run_deseq}
dds = DESeq2.DESeq(dds)
```


Get results:
```{python get_results}
contrastv = robjects.StrVector(["sm_name", sm_name, control_name])
res = DESeq2.results(dds, contrast=contrastv)

base = importr('base')
res = base.as_data_frame(res)
```

Preview results:
```{python preview_results}
dplyr = importr('dplyr')
utils = importr('utils')

res = utils.head(dplyr.arrange(res, 'padj'), 10)
```

Write to disk: this again requires the pandas2ri converter to convert the results to a pandas dataframe.
```{python write_results, eval=FALSE}
with (robjects.default_converter + pandas2ri.converter).context():
    res_pd = robjects.conversion.get_conversion().rpy2py(res)

    res_pd.to_csv("../usecase/data/de_contrasts.csv")
```

### Usecase: theoretical reticulate example

```{r read_in}
library(anndata)

adata_path <- "../usecase/data/sc_counts_subset.h5ad"
adata <- anndata::read_h5ad(adata_path)
```

Subset to a single small molecule and control for computational efficiency:

```{r select_sm_celltype}
library(dplyr)

sm_name <- "Belinostat"
control_name <- "Dimethyl Sulfoxide"

# subset obs
adata <- adata[adata$obs$sm_name %in% c(control_name, sm_name), adata$var$highly_variable]
```

```{r import_pandas}
library(reticulate)
pd <- import("pandas", convert = FALSE)

counts <- as.matrix(adata$X)
```

Combine data in a single data frame and compute pseudobulk
This is a literal translation of the Python code. It is however absolute madness to construct a pandas dataframe in R instead of using just an R dataframe. We basically just needed a matrix with rownames and columnames.

We provide the rest of the code as a theoretical example, but please reflect if you want to try something similar.

We will however showcase a useful application of reticulate.

```{r compute_pseudobulk, eval = FALSE}

combined <- pd$DataFrame(
  counts,
  index = adata$obs["plate_well_celltype_reannotated"],
  columns = adata$var_names
)
cr <- py_to_r(combined)

# we lost the rownames
rownames(cr) <- adata$obs_names
cr["celltype"] <- adata$obs["plate_well_celltype_reannotated"]

pb_X <- group_by(cr, celltype) %>% summarise(across(where(is.numeric), sum))
```

```{r pb_obs_r, eval = FALSE}
pb_obs <- adata$obs[c("sm_name", "cell_type", "plate_name", "well", "plate_well_celltype_reannotated")]
pb_obs <- pb_obs[!duplicated(pb_obs), ]
```

```{python pb_obs_py, eval = FALSE}
pb_obs = adata.obs[["sm_name", "cell_type", "plate_name", "well"]].copy()
pb_obs.index = adata.obs["plate_well_celltype_reannotated"]
pb_obs = pb_obs.drop_duplicates()
```

```{r pb_anndata, eval = FALSE}
select_X <- pb_X[pb_X$celltype %in% pb_obs$plate_well_celltype_reannotated, ]
select_X <- select_X %>% select(-"celltype")

pb_adata <- anndata::AnnData(
  X = select_X,
  obs = pb_obs,
  var = adata$var
)
```

<!-- note: don't remove the `eval=FALSE` for this one, as not to overwrite the usecase data -->
```{r store_pseudobulk, eval=FALSE}
write_h5ad(pb_adata, "../usecase/data/pseudobulk.h5ad")

```

### Usecase: useful reticulate example
